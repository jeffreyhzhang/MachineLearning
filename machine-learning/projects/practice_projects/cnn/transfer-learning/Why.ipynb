{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:85: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "208/208 [==============================] - 3089s 15s/step - loss: 2.1098 - acc: 0.5138 - val_loss: 0.7792 - val_acc: 0.7641\n",
      "Epoch 2/3\n",
      "208/208 [==============================] - 3077s 15s/step - loss: 0.8985 - acc: 0.7260 - val_loss: 0.5449 - val_acc: 0.8156\n",
      "Epoch 3/3\n",
      "208/208 [==============================] - 3044s 15s/step - loss: 0.7133 - acc: 0.7785 - val_loss: 0.6119 - val_acc: 0.8060\n",
      "\n",
      "Test accuracy: 79.9043%\n"
     ]
    }
   ],
   "source": [
    "###standalone...why it works on local?\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn.datasets import load_files \n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image                        \n",
    "from keras.preprocessing.image import img_to_array  \n",
    "from keras.applications import InceptionV3 \n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD  \n",
    "from PIL import ImageFile    \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
    "\n",
    "targetsize = (299,299)\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('dogImages/train')\n",
    "valid_files, valid_targets = load_dataset('dogImages/valid')\n",
    "test_files, test_targets = load_dataset('dogImages/test')\n",
    "\n",
    "def path_to_tensor(img_path,targetsize=targetsize):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=targetsize)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (w, h, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, w, h, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths,targetsize=targetsize):\n",
    "    list_of_tensors = [path_to_tensor(img_path,targetsize) for img_path in img_paths]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "\n",
    "def bestdog_predict_breed(modelname, img_file, target_size):\n",
    "    img_file = image.load_img(img_file, target_size=(299, 299))\n",
    "    if img_file.size != target_size:\n",
    "        img_file = img_file.resize(target_size)\n",
    "    x = image.img_to_array(img_file)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = modelname.predict(x)\n",
    "    return  np.argmax(preds[0])\n",
    "\n",
    "\n",
    "# create and configure augmented image generator\n",
    "datagen_train = ImageDataGenerator(\n",
    "    width_shift_range=0.1,   # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True)    # randomly flip images horizontally\n",
    "\n",
    "# create and configure augmented image generator\n",
    "datagen_valid = ImageDataGenerator(\n",
    "    width_shift_range=0.1,   # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True)    # randomly flip images horizontally\n",
    "\n",
    "# fit augmented image generator on data\n",
    "# pre-process the data for Keras to 4D tensor\n",
    "train_tensors = paths_to_tensor(train_files,targetsize).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files,targetsize).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files,targetsize).astype('float32')/255\n",
    " \n",
    "datagen_train.fit(train_tensors)\n",
    "datagen_valid.fit(valid_tensors)\n",
    "\n",
    "##########\n",
    "\n",
    "def add_new_last_layer(base_model, nb_classes,fullyconnected_size):\n",
    "    # add hidden layer \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(fullyconnected_size, activation='relu')(x) \n",
    "    predictions = Dense(nb_classes, activation='softmax')(x) \n",
    "    model = Model(input=base_model.input, output=predictions)\n",
    "    return model\n",
    "\n",
    "#Freeze all layers and compile the model\n",
    "def setup_to_transfer_learn(model, base_model):   \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#fine tune the model....retrain model after IV3_LAYERS_TO_FREEZE layers\n",
    "def setup_to_finetune(model,IV3_LAYERS_TO_FREEZE):\n",
    "    for layer in model.layers[:IV3_LAYERS_TO_FREEZE]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[IV3_LAYERS_TO_FREEZE:]:\n",
    "        layer.trainable = True\n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "batch_size = 32\n",
    "epochs = 1 \n",
    "nb_classes = 133\n",
    "fullyconnected_size=1024\n",
    "iv3_layers_to_freeze = 248\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False) #include_top=False excludes final Fully Connected layer\n",
    "#base_model.output.shape......(?, ?, ?, 2048)\n",
    "bestmodel = add_new_last_layer(base_model, nb_classes, fullyconnected_size)\n",
    "\n",
    "# transfer learning\n",
    "setup_to_transfer_learn(bestmodel, base_model)\n",
    "\n",
    "##### train model\n",
    "bestmodel.fit_generator(datagen_train.flow(train_tensors, train_targets, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(train_files) // batch_size,\n",
    "                    epochs=3, verbose=1, \n",
    "                    #callbacks=[checkpointer],\n",
    "                    validation_data=datagen_valid.flow(valid_tensors, valid_targets, batch_size=batch_size),\n",
    "                    validation_steps=len(valid_files) // batch_size)\n",
    "#save model with just argumented images, this will see any improvement from original base_model                       \n",
    "bestmodel.save(\"bestofbest0_InceptionV3.model\")\n",
    " \n",
    "    \n",
    "best_predictions = []\n",
    "best_output=np.zeros((len(test_files),133))\n",
    "for img in test_files:\n",
    "    best_predictions.append(bestdog_predict_breed(bestmodel,img, (299,299)))\n",
    "   \n",
    "  \n",
    "\n",
    "test_accuracy = 100*np.sum(np.array(best_predictions) ==\n",
    "                           np.argmax(test_targets, axis=1))/len(best_predictions)\n",
    "print('\\nTest accuracy: %.4f%%' % test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "208/208 [==============================] - 3474s 17s/step - loss: 0.4618 - val_loss: 0.4696\n",
      "\n",
      "Test accuracy: 85.1675%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fine-tuning\n",
    "setup_to_finetune(bestmodel, iv3_layers_to_freeze)\n",
    " \n",
    "# train the model\n",
    "#checkpointer = ModelCheckpoint(filepath='saved_models/bestofbest_InceptionV3_weights', verbose=1, save_best_only=True)\n",
    "\n",
    "bestmodel.fit_generator(datagen_train.flow(train_tensors, train_targets, batch_size=batch_size),\n",
    "                    steps_per_epoch= len(train_files) // batch_size,\n",
    "                    epochs=epochs, verbose=1,\n",
    "                    #callbacks=[checkpointer],\n",
    "                    validation_data=datagen_valid.flow(valid_tensors, valid_targets, batch_size=batch_size),\n",
    "                    validation_steps=len(valid_files) // batch_size)\n",
    "bestmodel.save(\"bestofbest1_InceptionV3.model\")\n",
    "\n",
    "### TODO: Calculate classification accuracy on the test dataset.\n",
    "best_predictions = []\n",
    "for img in test_files:\n",
    "    best_predictions.append(bestdog_predict_breed(bestmodel,img, (299,299)))\n",
    "   \n",
    "# report test accuracy...test files matching test_targets\n",
    "\n",
    "test_accuracy = 100*np.sum(np.array(best_predictions) ==\n",
    "                           np.argmax(test_targets, axis=1))/len(best_predictions)\n",
    "print('\\nTest accuracy: %.4f%%' % test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6680, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.60784316 0.61960787 0.69411767]\n",
      "  [0.6313726  0.61960787 0.69411767]\n",
      "  [0.6509804  0.6431373  0.7254902 ]\n",
      "  ...\n",
      "  [0.57254905 0.58431375 0.65882355]\n",
      "  [0.5764706  0.5882353  0.6627451 ]\n",
      "  [0.5529412  0.5803922  0.6509804 ]]\n",
      "\n",
      " [[0.6627451  0.67058825 0.7294118 ]\n",
      "  [0.6392157  0.63529414 0.69803923]\n",
      "  [0.6392157  0.6509804  0.7176471 ]\n",
      "  ...\n",
      "  [0.5568628  0.58431375 0.654902  ]\n",
      "  [0.5529412  0.57254905 0.64705884]\n",
      "  [0.5411765  0.5686275  0.6392157 ]]\n",
      "\n",
      " [[0.5882353  0.59607846 0.654902  ]\n",
      "  [0.6392157  0.63529414 0.6901961 ]\n",
      "  [0.6313726  0.6431373  0.7019608 ]\n",
      "  ...\n",
      "  [0.5529412  0.5882353  0.654902  ]\n",
      "  [0.5568628  0.5764706  0.6509804 ]\n",
      "  [0.54509807 0.57254905 0.64705884]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.13333334 0.12156863 0.05490196]\n",
      "  [0.14509805 0.14117648 0.07058824]\n",
      "  [0.14117648 0.1254902  0.08235294]\n",
      "  ...\n",
      "  [0.6117647  0.60784316 0.6627451 ]\n",
      "  [0.60784316 0.6039216  0.6666667 ]\n",
      "  [0.6117647  0.63529414 0.6901961 ]]\n",
      "\n",
      " [[0.14117648 0.12941177 0.05490196]\n",
      "  [0.15686275 0.13725491 0.0627451 ]\n",
      "  [0.15294118 0.12941177 0.07450981]\n",
      "  ...\n",
      "  [0.5921569  0.6039216  0.6627451 ]\n",
      "  [0.59607846 0.6        0.6784314 ]\n",
      "  [0.6117647  0.62352943 0.6901961 ]]\n",
      "\n",
      " [[0.13333334 0.12156863 0.0627451 ]\n",
      "  [0.14901961 0.1254902  0.07058824]\n",
      "  [0.14509805 0.12156863 0.07450981]\n",
      "  ...\n",
      "  [0.6039216  0.6156863  0.6745098 ]\n",
      "  [0.6        0.6039216  0.68235296]\n",
      "  [0.60784316 0.627451   0.7019608 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_tensors[0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
